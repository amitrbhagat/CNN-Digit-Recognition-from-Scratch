{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d6284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe80c3f",
   "metadata": {},
   "source": [
    "#### Fetch the openml digit recognition data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e3ee82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "data = fetch_openml('mnist_784', as_frame=False)\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61a408a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000, 784)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aabc3a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44038af0",
   "metadata": {},
   "source": [
    "#### Splitting the data into x_train, y_train, x_test, y_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ca24729",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X[:60000]\n",
    "y_train = y[:60000]\n",
    "\n",
    "x_test = X[60000:]\n",
    "y_test = y[60000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9040fd5",
   "metadata": {},
   "source": [
    "##### Converting the datset x_train and x_test dataset into 3 channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fa1ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(-1, 28, 28)\n",
    "x_test = x_test.reshape(-1, 28, 28)\n",
    "\n",
    "x_train = x_train[:, :, :, np.newaxis]\n",
    "x_test  = x_test[:, :, :, np.newaxis]\n",
    "\n",
    "x_train = np.repeat(x_train, 3, axis=3)\n",
    "x_test = np.repeat(x_test, 3, axis=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8943d6fb",
   "metadata": {},
   "source": [
    "##### Adding zero padding to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "028f57f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the function to add zero padding to the training dataset\n",
    "\n",
    "def zero_pad(X, pad):\n",
    "    # Adding the zero padding of size pad to the height and width of X\n",
    "\n",
    "    X_pad = np.pad(X, ((0, 0), (pad, pad), (pad, pad), (0, 0)), mode = 'constant', constant_values = (0, 0))\n",
    "    # returning X_pad\n",
    "    return X_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b251553",
   "metadata": {},
   "source": [
    "#### Single step convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ee06af",
   "metadata": {},
   "source": [
    "Here we are creating single step convolution operation where kernel window is applied on the previous input image and multiply and added the all the pixel values from the input image. It will result into the output which is reduced version of the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09743558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_single_step(a_prev_slice, W, b):\n",
    "    #apply window W over a_prev_slice\n",
    "    s = a_prev_slice * W\n",
    "    Z = np.sum(s) + float(b)\n",
    "    Z = np.float64(Z)\n",
    "\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fae6a2",
   "metadata": {},
   "source": [
    "#### Forward propagation in convolution neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaee0a4",
   "metadata": {},
   "source": [
    "In forward convolution forward prop we building the function to convolve the kernal over the previous layer activation. Also defining the output shape of convolution to store the Conv_single _step into the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1a517ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_forward(A_prev, W, b, hparameters):\n",
    "\n",
    "    # Retrieve the dimensions of the A_prev's shape\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "    \n",
    "    # Retrieve the dimensions of the W shape\n",
    "    (f, f, n_C_prev, n_C) = W.shape\n",
    "\n",
    "    #Retrieve strides and pad from hparameters\n",
    "    strides = hparameters[\"stride\"]\n",
    "    pad = hparameters[\"pad\"]\n",
    "\n",
    "    #Declare the dimensions of the output and Create the output with the given dimension\n",
    "    n_H = int((n_H_prev - f + 2 * pad)/strides) + 1\n",
    "    n_W = int((n_W_prev - f + 2 * pad)/strides) + 1\n",
    "\n",
    "    Z = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "    #Add zero padding to the previous layer activation using zero_pad function\n",
    "    A_prev_pad = zero_pad(A_prev, pad)\n",
    "\n",
    "    #Loop over the batch of training examples\n",
    "    for i in range(m):\n",
    "        a_prev_pad = A_prev_pad[i]   #selecting the single example\n",
    "\n",
    "        #Loop over the vertical axis of output volume\n",
    "        for h in range(n_H):\n",
    "            vert_start = strides * h   #defining the vertical start and end\n",
    "            vert_end = vert_start + f\n",
    "\n",
    "            #Loop over the horizontal axis of output volumn\n",
    "            for w in range(n_W):\n",
    "                horiz_start = strides * w\n",
    "                horiz_end = horiz_start + f\n",
    "\n",
    "                #Loop over the number of filters\n",
    "                for c in range(n_C):\n",
    "                    #selecting the slice from the a_prev_pad to convolve the window\n",
    "                    a_prev_slice = a_prev_pad[vert_start:vert_end, horiz_start:horiz_end, :]\n",
    "\n",
    "                    #selecting the parameters W and b and perform Conv_single_step\n",
    "                    weights = W[:, :, :, c]\n",
    "                    biases = b[:, :, :, c]\n",
    "                    Z[i, h, w, c] = conv_single_step(a_prev_slice, weights, biases)\n",
    "    \n",
    "    #Save information in cache for backprop \n",
    "    cache = (A_prev, W, b, hparameters)\n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3409a",
   "metadata": {},
   "source": [
    "### Forward pooling in convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba505cb",
   "metadata": {},
   "source": [
    "The pooling layer reduces the height and width of the input. It helps to reduce the computatuion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e7acd6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementing forward pooling function\n",
    "def pool_forward(A_prev, hparameters, mode = \"max\"):\n",
    "\n",
    "    #Retrieve the dimensions of the previous activation\n",
    "    (m, n_H_prev, n_W_prev, n_C_prev) = A_prev.shape\n",
    "\n",
    "    #Retrieve hyperparameters from hparameters\n",
    "    f = hparameters[\"f\"]\n",
    "    stride = hparameters[\"stride\"]\n",
    "\n",
    "    #Define Dimensions of the output\n",
    "    n_H = int(1 + (n_H_prev - f) / stride)\n",
    "    n_W = int(1 + (n_W_prev - f) / stride)\n",
    "    n_C = n_C_prev\n",
    "\n",
    "    #Initialize the output matrix A\n",
    "    A = np.zeros((m, n_H, n_W, n_C))\n",
    "\n",
    "    #Loop over the input examples in A_prev\n",
    "    for i in range(m):\n",
    "        a_prev = A_prev[i]\n",
    "\n",
    "        #Loop over the vertical axis of output volumn\n",
    "        for h in range(n_H):\n",
    "            vert_start = stride * h\n",
    "            vert_end = vert_start + f\n",
    "\n",
    "            #Loop over the horizontal axis of output volumn\n",
    "            for w in range(n_W):\n",
    "                horiz_start = stride * w\n",
    "                horiz_end = horiz_start + f\n",
    "\n",
    "                #Loop over the number of channels of output volumn\n",
    "                for c in range(n_C):\n",
    "                     a_prev_slice = a_prev[\n",
    "                        vert_start:vert_end, \n",
    "                        horiz_start:horiz_end, \n",
    "                        c\n",
    "                        ]\n",
    "\n",
    "                     if mode == \"max\":\n",
    "                         A[i, h, w, c] = np.max(a_prev_slice)\n",
    "                     elif mode == \"average\":\n",
    "                         A[i, h, w, c] = np.mean(a_prev_slice)\n",
    "\n",
    "    cache = (A_prev, hparameters)\n",
    "\n",
    "    return A, cache            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
